{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64a78067-b02e-4583-9b16-d536d1f946ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import transformers\n",
    "from dotenv import load_dotenv\n",
    "# from langchain.agents import create_csv_agent\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "import torch\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "text_loader_kwargs={'autodetect_encoding': True}\n",
    "loader = DirectoryLoader('/Volumes/feedback/default/test', \n",
    "    loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 1,\n",
    "    chunk_overlap  = 0,\n",
    "    length_function = lambda x: 1, # usually len is used \n",
    "    is_separator_regex = False\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "# Assuming docs is a pandas DataFrame\n",
    "df = pd.DataFrame(split_docs)\n",
    "\n",
    "# Modify the docs to split reviews into rows\n",
    "modified_docs = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    # Access the content from the first column (assuming the content is in the first column and it's a tuple)\n",
    "    content_tuple = row[0]\n",
    "    \n",
    "    # Access the actual content (assuming it's the first element of the tuple)\n",
    "    content = content_tuple[1]\n",
    "    \n",
    "    # Assuming each review is separated by a newline character '\\n'\n",
    "    reviews = content.split('\\t')\n",
    "    \n",
    "    # Remove any empty reviews\n",
    "    reviews = [review.strip() for review in reviews if review.strip()]\n",
    "    \n",
    "    # Add the modified document with reviews as separate rows\n",
    "    modified_docs.append(reviews)\n",
    "\n",
    "data = pd.DataFrame(modified_docs).fillna('unknown')\n",
    "data[\"review\"] = data[1]+data[2]\n",
    "\n",
    "spark_df = spark.createDataFrame(data[\"review\"])\n",
    "# spark.sql(\"CREATE DATABASE IF NOT EXISTS hotel\")\n",
    "spark_df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"hive_metastore.chatbot.review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e35cc37b-9522-408a-b0d1-e6104fa38885",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "{\n",
    "\"review\":'''Efficient and Affordable Chatbot Solution\n",
    "Tried out this chatbot for a project, and it exceeded expectations. The platform is a bit remote in terms of user interface, but if you're willing to invest a bit of time to navigate, it's an excellent value for money. No need to worry about additional costs â€“ the service is budget-friendly, and the chatbot's responses are modern, clear, and efficient. The interface is user-friendly, making it a great choice for those who don't want to splurge on a high-end AI service but still seek a reliable and functional chatbot solution. Additionally, the platform offers free integration with other tools, a definite plus for users looking to streamline their processes.''',\n",
    "\"aspects\":'''Relevant Aspects are user interface, affordability, value for money, efficiency, user-friendliness, integration options, target audience'''\n",
    "},\n",
    "{\n",
    "\"review\":'''Accessible and Budget-Friendly Language Learning Chatbot\n",
    "Recently used this language learning chatbot and was pleasantly surprised. While the platform may seem a bit remote in terms of the app store, it's an unbeatable option for those on a budget. The chatbot provides a cost-effective way to practice and improve language skills without shelling out for expensive courses. The lessons are modern, interactive, and the user interface, although not as flashy as premium options, is intuitive and straightforward. Plus, the chatbot offers free additional resources, making it an excellent choice for language enthusiasts looking for quality without breaking the bank.''',\n",
    "\"aspects\":'''Relevant Aspects are app store accessibility, budget-friendliness, value for money, lesson quality, user interface, free resources, target audience'''\n",
    "}\n",
    "]\n",
    "\n",
    "prompt_template='''\n",
    "Review:{review}\n",
    "{aspects}\n",
    "'''\n",
    "example_prompt = PromptTemplate(input_variables=['review','aspects'],template=prompt_template)\n",
    "\n",
    "final_prompt = FewShotPromptTemplate(\n",
    "examples=examples,\n",
    "example_prompt = example_prompt,\n",
    "suffix=\"Review: {review}\\n\",\n",
    "input_variables= [\"review\"],\n",
    "prefix= \"Analyze the provided chotbot review and identify the following aspects: User interface, App store accessibility, Affordability, Value for money, Efficiency, User-friendliness, and Integration options. Perform sentiment analysis on each aspect, assigning sentiment labels ['positive', 'negative', 'neutral'] based on the reviewer's opinion. Next please show the evidence from the review for sentiment labels. The final output should consist of pairs, associating each mentioned aspect with its corresponding sentiment label and evidence, presented as (aspect, sentiment label, evidence). For example, if the review mentions that the User interface is 'convenient', the output should include (User interface, positive, 'convenient'). Just return result in dict format. Aspects not explicitly mentioned in the review should be excluded from the output.\"\n",
    ")\n",
    "\n",
    "# model_local_path = \"databricks/dolly-v2-12b\" \n",
    "\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained(model_local_path)\n",
    "\n",
    "# pipeline = transformers.pipeline(\"text-generation\",\n",
    "#                                   model=model_local_path,\n",
    "#                                   tokenizer=tokenizer,\n",
    "#                                   torch_dtype=torch.bfloat16,\n",
    "#                                   trust_remote_code=True,\n",
    "#                                   device_map=\"auto\",\n",
    "#                                   max_new_tokens=1000)\n",
    "\n",
    "# local_llm = HuggingFacePipeline(pipeline=pipeline)\n",
    "\n",
    "# llm=OpenAI(model_name = 'text-davinci-003',openai_api_key=OPENAI_API_KEY)\n",
    "# Initiate a connection to the LLM from Azure OpenAI Service via LangChain.\n",
    "llm = OpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    model_name=model_name,\n",
    "    openai_api_version=api_version,\n",
    "    engine=\"gpt-4\"\n",
    ")\n",
    "\n",
    "aspects_extraction_chain = LLMChain(llm=llm, prompt = final_prompt, output_key='aspects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d74b3177-5c82-4147-98ca-fba9f8a87f15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the CSV file into a pandas DataFrame\n",
    "reviews_df = pd.DataFrame(data['review']).iloc[0:10]\n",
    "\n",
    "# Initialize an empty list to store the predictions\n",
    "predictions = []\n",
    "\n",
    "# Iterate over each review in the DataFrame\n",
    "for i in reviews_df['review']:\n",
    "    # Generate predictions for the current review\n",
    "    output = aspects_extraction_chain.predict(review=i)\n",
    "\n",
    "    prediction_dict = {'review': i, 'aspect,sentiment,evidence': output}\n",
    "    predictions.append(prediction_dict)\n",
    "\n",
    "# Convert the predictions list into a pandas DataFrame\n",
    "predictions_df = pd.DataFrame(predictions)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ABSA",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
